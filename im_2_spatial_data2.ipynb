{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from tifffile import imread\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from spatialdata import SpatialData \n",
    "from spatialdata.models import Image2DModel, Labels2DModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Renaming Core Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path(r'R:\\Wayne\\BLCA')\n",
    "CORE_STORAGE_NAME = \"Core_Storage\"\n",
    "SEGMENTATION_STORAGE_NAME = \"Segmentation Storage\"\n",
    "VALID_IMAGE_EXT = \".tif\"\n",
    "VALID_MARKERS = [\"Cy\", \"DAPI\", \"FITC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function that creates list of files that need name change\n",
    "def find_valid_files(core_path: Path, verbose = False) -> list[Path]:\n",
    "    valid_files = [] \n",
    "    for file in core_path.iterdir():\n",
    "        if file.suffix == VALID_IMAGE_EXT:\n",
    "            #adds file if it has at least one marker\n",
    "            for marker in VALID_MARKERS:\n",
    "                if marker in file.name:\n",
    "                    valid_files.append(file)\n",
    "                    break\n",
    "    if verbose:\n",
    "        print(f\"{len(valid_files)} valid files found in {core_path.name}\")\n",
    "    return sorted(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to check whether a folder is a valid BCLA analysis folder\n",
    "#based on presence of a core storage folder\n",
    "def valid_analysis_folder(folder_path: Path, verbose = False) -> bool:\n",
    "    core_storage_path = folder_path / CORE_STORAGE_NAME\n",
    "    is_valid = folder_path.is_dir() and core_storage_path.is_dir()\n",
    "    if verbose:\n",
    "        if is_valid:\n",
    "            print(f\"Analysis folder found: {folder_path.name}\")\n",
    "        else:\n",
    "            print(f\"Skipped: {folder_path.name}\")\n",
    "\n",
    "    return is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to check whether a core folder is valid \n",
    "#based on presence of segmentation file\n",
    "def valid_core_folder(folder_path : Path, verbose = False) -> bool:\n",
    "    segmentation_path = folder_path / SEGMENTATION_STORAGE_NAME\n",
    "    is_valid = folder_path.is_dir() and segmentation_path.is_dir()\n",
    "    if verbose:\n",
    "        if is_valid:\n",
    "            print(f\"Core folder found: {folder_path.name}\")\n",
    "        else:\n",
    "            print(f\"Skipped: {folder_path.name}\")\n",
    "    return is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming images function \n",
    "def rename_BCLA_images(root_dir = ROOT_DIR, dry_run = True, verbose = True ) -> list[Path]:\n",
    "    renamed_images = []\n",
    "\n",
    "    #dictionary to store old path -> new path\n",
    "    rename_map = {}\n",
    "\n",
    "    #loop traversing through each analysis folder inside BCLA folder\n",
    "    for item in sorted(root_dir.iterdir()):\n",
    "        if not valid_analysis_folder(item, verbose = verbose):\n",
    "            continue\n",
    "\n",
    "        core_storage_path = item / CORE_STORAGE_NAME\n",
    "\n",
    "        #loop through each core in Core_Storage\n",
    "        for core_path in sorted(core_storage_path.iterdir()):\n",
    "\n",
    "            if not valid_core_folder(core_path, verbose = verbose):\n",
    "                continue\n",
    "            \n",
    "            #find & rename the images in core folders\n",
    "            for image_path in find_valid_files(core_path, verbose = verbose):\n",
    "                 #find round number and antibody name\n",
    "                match = re.search(r'_(\\d+)\\.0\\.4_.*?_(\\w+)-', image_path)\n",
    "                if match:\n",
    "                    #make round number 2 digits\n",
    "                    round_num = f\"{int(match.group(1)):02d}\"\n",
    "                    antibody = match.group(2)\n",
    "\n",
    "                    #establish the new image name\n",
    "                    new_name = f\"{round_num}_{antibody}.tif\"\n",
    "                    new_path = image_path.parent / new_name\n",
    "\n",
    "                    if image_path.name != new_name:\n",
    "                        if dry_run:\n",
    "                            print(f\"Would rename:\\n {image_path.name} -> {new_name}\")\n",
    "                        else:\n",
    "                            image_path.rename(new_path)\n",
    "                            renamed_images.append(new_path)\n",
    "                            rename_map[image_path] = new_path\n",
    "\n",
    "    #write the rename map dict into a txt file \n",
    "    if not dry_run and rename_map:\n",
    "        rename_map_path = ROOT_DIR / \"renamed_map.txt\"   \n",
    "        with open(rename_map_path, \"w\")as f:\n",
    "            for old_path, new_path, in rename_map.items():\n",
    "                f.write(f\"{old_path} -> {new_path}\\n\") \n",
    "        if verbose:\n",
    "            print(f\"Rename map saved to {rename_map_path}\")\n",
    "            \n",
    "    return renamed_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = rename_BCLA_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Uploading Image + Segmentation into SpatialData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spatial_data(core_path, output_path, chunk_size = (1, 4096, 4096), scale_factors = [2,4], dry_run = True):\n",
    "\n",
    "    #path to the segmentation folder\n",
    "    seg_folder = core_path / SEGMENTATION_STORAGE_NAME\n",
    "    #creates a list of all the tif segmentation files, should only contain 1\n",
    "    seg_files = list(seg_folder.glob(\"*.tif\"))\n",
    "\n",
    "    #skips the core if no seg file exists\n",
    "    if not seg_files:\n",
    "        return None\n",
    "    \n",
    "    #seg_files[0] bc the seg file should be the first and only file\n",
    "    #numpy array for seg files\n",
    "    seg_array = imread(seg_files[0])\n",
    "\n",
    "    #wrap the segmentation array into Label2DModel or xarray format\n",
    "    label_model = Labels2DModel.parse(seg_array, dims = ('c', 'y', 'x'), chunks = chunk_size, scale_factors = scale_factors)\n",
    "\n",
    "    #image files list\n",
    "    image_paths = find_valid_files(core_path)\n",
    "\n",
    "    #skips the core if no images found\n",
    "    if len(image_paths) == 0:\n",
    "        return None\n",
    "    \n",
    "    #image dictionary\n",
    "    #key = image name, value = image model\n",
    "    images_dict = {}\n",
    "    for img_path in image_paths:\n",
    "        #read into memory as numpy array\n",
    "        image_array = imread(img_path)\n",
    "        model_name = img_path.stem\n",
    "\n",
    "        #wrap the image array into Image2DModel or xarray format\n",
    "        image_model = Image2DModel.parse(image_array, dims = ('c', 'y', 'x'), chunks = chunk_size, scale_factors = scale_factors)\n",
    "        images_dict[model_name] = image_model\n",
    "\n",
    "    #after parsing, create actual spatial data object\n",
    "    sdata = SpatialData(images = images_dict, labels = {\"segmentation\": label_model})\n",
    "    \n",
    "    #dry run, does not actually upload\n",
    "    if dry_run:\n",
    "        print(f\"Would upload {output_path} into SpatialData\")\n",
    "        return None\n",
    "    else:\n",
    "        sdata.write(str(output_path), overwrite = True)\n",
    "        \n",
    "    return sdata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for analysis_folder in sorted(ROOT_DIR.iterdir()):\n",
    "      \n",
    "    #check is the folder is valid\n",
    "    if not valid_analysis_folder(analysis_folder):\n",
    "        continue\n",
    "\n",
    "    #restablishes where the core storage folders are\n",
    "    core_storage_path = analysis_folder / CORE_STORAGE_NAME\n",
    "\n",
    "    for core_path in sorted(core_storage_path.iterdir()):\n",
    "        if not valid_core_folder(core_path):\n",
    "             continue\n",
    "\n",
    "        #creating output path file name (folder name + .zarr)\n",
    "        core_name = core_path.name\n",
    "        output_path = core_path / f\"{core_name}.zarr\"\n",
    "\n",
    "        try:\n",
    "            sdata = load_spatial_data(core_path, output_path, dry_run = True)\n",
    "\n",
    "            #prints if sdata has a value and skipped if it doesnt\n",
    "            #if sdata is empty, likely means either image or seg files are missing\n",
    "            if sdata is not None:\n",
    "                print(f\"Successfully saved SpatialData for {core_name} -> {output_path}\")\n",
    "            else:\n",
    "                print(f\"Skipped {core_name} -> something missing\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing core: {core_name} : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
